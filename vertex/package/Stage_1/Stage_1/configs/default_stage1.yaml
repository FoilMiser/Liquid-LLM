resume_gcs_uri: null
output_gcs_uri: ./stage1_output
teacher: llama-3.1-8b
seq_len: 1024
net2net_width_pct: 10
add_blocks_classic: 2
add_blocks_liquid: 3
freeze_classic_after: true
use_flash_attn: true
use_grad_ckpt: true
precision: bfloat16
optimizer: adamw
lr: 0.00025
weight_decay: 0.1
betas: "0.9,0.95"
warmup_steps: 3000
max_steps: 120000
eval_every: 1000
save_every: 2000
kd_temperature: 2.0
kd_alpha_start: 0.7
kd_alpha_end: 0.4
kd_anneal_pct: 0.3
keep_old_logit_l2: 0.1
keep_old_logit_l2_fade_step: 30000
dataset_cfg: ./configs/stage1.jsonl
tool_use_ratio: 0.08
calculator_enabled: true
scratchpad_enabled: true
hf_secret_name: hf_token
batch_size: 16
eval_batch_size: 8
num_workers: 4
log_every: 100
best_metric: val_perplexity
best_metric_mode: min
use_checkpoint_saver: true
